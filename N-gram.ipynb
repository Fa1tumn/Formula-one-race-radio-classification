{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cafd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "733890c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터셋 (간단 예시)\n",
    "texts = [\n",
    "    \"Box box box\",\n",
    "    \"My tyres are gone\",\n",
    "    \"Tell him to get out\",\n",
    "    \"We need to push\",\n",
    "    \"Engine is overheating\",\n",
    "    \"Good job keep pushing\",\n",
    "    \"I'm losing power\",\n",
    "    \"Switching to plan B\",\n",
    "    \"Push now push now\",\n",
    "    \"Let me race please\"\n",
    "]\n",
    "labels = [\n",
    "    \"진입 명령\", \"차량 상태\", \"불만/요청\", \"전략/전술\", \"차량 상태\",\n",
    "    \"격려\", \"차량 상태\", \"전략/전술\", \"전략/전술\", \"불만/요청\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c21b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(text, n=2):\n",
    "    \"\"\"Generate n-grams from a given text.\"\"\"\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5167a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts, ngram_range=(1, 2)):\n",
    "    \"\"\"Build vocabulary for n-grams.\"\"\"\n",
    "    vocab = defaultdict(int)\n",
    "    for text in texts:\n",
    "        for n in range(ngram_range[0], ngram_range[1] + 1):\n",
    "            ngrams = generate_ngrams(text, n)\n",
    "            for ngram in ngrams:\n",
    "                vocab[ngram] += 1\n",
    "    return {word: idx for idx, word in enumerate(vocab.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34fe08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_texts(texts, vocab, ngram_range=(1, 2)):\n",
    "    \"\"\"Convert texts to vectorized form using the vocabulary.\"\"\"\n",
    "    vectors = []\n",
    "    for text in texts:\n",
    "        vec = np.zeros(len(vocab))\n",
    "        for n in range(ngram_range[0], ngram_range[1] + 1):\n",
    "            ngrams = generate_ngrams(text, n)\n",
    "            for ngram in ngrams:\n",
    "                if ngram in vocab:\n",
    "                    vec[vocab[ngram]] += 1\n",
    "        vectors.append(vec)\n",
    "    return np.array(vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
